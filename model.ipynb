{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bite4acc8a8f33c40ef89e2843604da7712",
   "display_name": "Python 3.8.5 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dir, label, train, test):\n",
    "    temp = []\n",
    "    count = 0\n",
    "    for pics in os.listdir(dir):\n",
    "        img = cv2.imread(os.path.join(dir, pics), cv2.IMREAD_COLOR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (220,220))\n",
    "        temp.append([img, label])           # using int: sparse categorical\n",
    "        count += 1\n",
    "    length = int(count * 0.1)\n",
    "    train += temp[length:]\n",
    "    test += temp[:length]\n",
    "    print(folder, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = []\n",
    "TEST.clear()\n",
    "TRAINVAL = []\n",
    "TRAINVAL.clear()\n",
    "\n",
    "path = \"/content/GarbageClassification/img/own\"\n",
    "for folder in os.listdir(path):\n",
    "    count = 0\n",
    "    temp = []\n",
    "    if \"trash\" in folder:\n",
    "        dir = os.path.join(path, folder)\n",
    "        create_dataset(dir, 4, TRAINVAL, TEST)\n",
    "    else:\n",
    "        dir = os.path.join(path, folder)\n",
    "        for sub in os.listdir(dir):\n",
    "            fold = os.path.join(dir, sub)\n",
    "            if \"glass\" in folder:\n",
    "                create_dataset(fold, 0, TRAINVAL, TEST)\n",
    "            elif \"metal\" in folder:\n",
    "                create_dataset(fold, 1, TRAINVAL, TEST)\n",
    "            elif \"paper\" in folder:\n",
    "                create_dataset(fold, 2, TRAINVAL, TEST)\n",
    "            elif \"plastic\" in folder:\n",
    "                create_dataset(fold, 3, TRAINVAL, TEST)\n",
    "        print(folder, count)\n",
    "\n",
    "print(\"TRAINVAL:\", len(TRAINVAL))\n",
    "print(\"TEST:\", len(TEST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINVAL = np.asarray(TRAINVAL)\n",
    "TEST = np.asarray(TEST)\n",
    "\n",
    "# training data augmentation\n",
    "augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(mode=\"horizontal_and_vertical\", seed=18),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(factor=0.2, seed=18),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomContrast(factor=0.5, seed=18)\n",
    "])\n",
    "\n",
    "added = []\n",
    "for i in range(len(TRAINVAL)):\n",
    "    image = tf.expand_dims(TRAINVAL[i][0], axis=0)\n",
    "    augmented = augmentation(image)\n",
    "    augmented = np.asarray(augmented[0])\n",
    "    added.append([augmented, TRAINVAL[i][1]])\n",
    "\n",
    "added = np.asarray(added)\n",
    "\n",
    "# # add augmented data to training data and shuffle\n",
    "print(TRAINVAL.shape, added.shape)\n",
    "TRAINVAL = np.concatenate((TRAINVAL, added))\n",
    "print(TRAINVAL.shape)\n",
    "np.random.shuffle(TRAINVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate train and val\n",
    "length = int(len(TRAINVAL) * 0.1)\n",
    "train = TRAINVAL[length:]\n",
    "val = TRAINVAL[:length]\n",
    "\n",
    "# separate feature and label\n",
    "TRAINVAL = []   # clear array\n",
    "xtrain = []\n",
    "ytrain = []\n",
    "for feature, label in train:\n",
    "    xtrain.append(feature)\n",
    "    ytrain.append(label)\n",
    "xtrain = np.asarray(xtrain)\n",
    "ytrain = np.asarray(ytrain)\n",
    "\n",
    "xval = []\n",
    "yval = []\n",
    "for feature, label in val:\n",
    "    xval.append(feature)\n",
    "    yval.append(label)\n",
    "xval = np.asarray(xval)\n",
    "yval = np.asarray(yval)\n",
    "\n",
    "xtest = []\n",
    "ytest = []\n",
    "for feature, label in TEST:\n",
    "    xtest.append(feature)\n",
    "    ytest.append(label)\n",
    "xtest = np.asarray(xtest)\n",
    "ytest = np.asarray(ytest)\n",
    "TEST = []       # clear array\n",
    "\n",
    "print(xtrain.shape, ytrain.shape)\n",
    "print(xval.shape, yval.shape)\n",
    "print(xtest.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = tf.keras.applications.MobileNet(\n",
    "    include_top = False, \n",
    "    weights = 'imagenet',\n",
    "    input_shape = (220,220,3)\n",
    ")\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(resnet)\n",
    "model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(5, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001), \n",
    "    loss = 'sparse_categorical_crossentropy', \n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, restore_best_weights=True, patience=3)\n",
    "\n",
    "history = model.fit(xtrain, ytrain, \n",
    "                    batch_size=32, \n",
    "                    epochs=30,\n",
    "                    callbacks=callback, \n",
    "                    validation_data=(xval,yval))\n",
    "\n",
    "path = F\"/content/gdrive/MyDrive/Colab Notebooks/saved_model/10 - Resnet/mobilenet4.h5\"     # path to save model\n",
    "model.save(path)\n",
    "\n",
    "# accuracy graph\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# loss graph\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(xtest)\n",
    "\n",
    "correct = 0\n",
    "wrong_index = []\n",
    "predicted_index = []\n",
    "\n",
    "for i in range(len(prediction)):\n",
    "    temp = np.argmax(prediction[i])\n",
    "    if (temp == ytest[i]):\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong_index.append(i)\n",
    "        predicted_index.append(temp)\n",
    "\n",
    "print(\"accuracy: \", correct / len(xtest) * 100)\n",
    "print(wrong_index)\n",
    "print(predicted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 6\n",
    "rows = int(len(wrong_index) / cols) + 1\n",
    "axes = []\n",
    "figs = plt.figure(figsize=(17,10))\n",
    "\n",
    "labels = [\"glass\", \"metal\", \"paper\", \"plastic\", \"trash\"]\n",
    "\n",
    "for i in range(rows * cols):\n",
    "    if(i < len(wrong_index)):\n",
    "        axes.append(figs.add_subplot(rows, cols, i+1))\n",
    "        pic = xtest[wrong_index[i]]\n",
    "        name = labels[predicted_index[i]]\n",
    "        axes[-1].set_title(name)\n",
    "        plt.imshow(pic)\n",
    "plt.show()"
   ]
  }
 ]
}